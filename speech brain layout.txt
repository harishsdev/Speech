.
├── sample_data
│   ├── anscombe.json
│   ├── california_housing_test.csv
│   ├── california_housing_train.csv
│   ├── mnist_test.csv
│   ├── mnist_train_small.csv
│   └── README.md
└── speechbrain
    ├── conftest.py
    ├── docs
    │   ├── _apidoc_templates
    │   │   ├── module.rst
    │   │   └── package.rst
    │   ├── conf.py
    │   ├── contributing.md
    │   ├── docs-requirements.txt
    │   ├── experiment.md
    │   ├── images
    │   │   └── logo_noname_rounded_big.png
    │   ├── index.rst
    │   ├── installation.md
    │   ├── Makefile
    │   ├── multigpu.md
    │   ├── README.md
    │   └── tutorials.md
    ├── LICENSE
    ├── lint-requirements.txt
    ├── pyproject.toml
    ├── pytest.ini
    ├── README.md
    ├── recipes
    │   ├── AISHELL-1
    │   │   ├── ASR
    │   │   │   ├── seq2seq
    │   │   │   │   ├── hparams
    │   │   │   │   │   └── train.yaml
    │   │   │   │   ├── prepare.py -> ../../prepare.py
    │   │   │   │   ├── README.md
    │   │   │   │   └── train.py
    │   │   │   └── transformer
    │   │   │       ├── hparams
    │   │   │       │   ├── train_ASR_transformer_with_wav2vect.yaml
    │   │   │       │   └── train_ASR_transformer.yaml
    │   │   │       ├── prepare.py -> ../../prepare.py
    │   │   │       ├── README.md
    │   │   │       ├── train.py
    │   │   │       └── train_with_wav2vect.py
    │   │   ├── prepare.py
    │   │   └── Tokenizer
    │   │       ├── hparams
    │   │       │   ├── tokenizer_bpe5000.yaml
    │   │       │   └── train_transformer_tokenizer_bpe5000.yaml
    │   │       ├── prepare.py -> ../prepare.py
    │   │       ├── pretrained.py
    │   │       └── train.py
    │   ├── AMI
    │   │   ├── ami_prepare.py
    │   │   ├── ami_splits.py
    │   │   └── Diarization
    │   │       ├── ami_prepare.py -> ../ami_prepare.py
    │   │       ├── experiment.py
    │   │       ├── extra_requirements.txt
    │   │       ├── hparams
    │   │       │   ├── ecapa_tdnn.yaml
    │   │       │   └── xvectors.yaml
    │   │       └── README.md
    │   ├── CommonLanguage
    │   │   ├── common_language_prepare.py
    │   │   ├── lang_id
    │   │   │   ├── common_language_prepare.py -> ../common_language_prepare.py
    │   │   │   ├── hparams
    │   │   │   │   └── train_ecapa_tdnn.yaml
    │   │   │   ├── README.md
    │   │   │   └── train.py
    │   │   └── README.md
    │   ├── CommonVoice
    │   │   ├── ASR
    │   │   │   ├── CTC
    │   │   │   │   ├── common_voice_prepare.py -> ../../common_voice_prepare.py
    │   │   │   │   ├── hparams
    │   │   │   │   │   ├── train_en_with_wav2vec.yaml
    │   │   │   │   │   ├── train_fr_with_wav2vec.yaml
    │   │   │   │   │   ├── train_it_with_wav2vec.yaml
    │   │   │   │   │   └── train_rw_with_wav2vec.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   └── train_with_wav2vec.py
    │   │   │   ├── seq2seq
    │   │   │   │   ├── common_voice_prepare.py -> ../../common_voice_prepare.py
    │   │   │   │   ├── hparams
    │   │   │   │   │   ├── train_en_with_wav2vec.yaml
    │   │   │   │   │   ├── train_en.yaml
    │   │   │   │   │   ├── train_fr_with_wav2vec.yaml
    │   │   │   │   │   ├── train_fr.yaml
    │   │   │   │   │   ├── train_it_with_wav2vec.yaml
    │   │   │   │   │   ├── train_it.yaml
    │   │   │   │   │   ├── train_rw_with_wav2vec.yaml
    │   │   │   │   │   └── train_rw.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   ├── train.py
    │   │   │   │   └── train_with_wav2vec.py
    │   │   │   ├── transducer
    │   │   │   │   ├── common_voice_prepare.py -> ../../common_voice_prepare.py
    │   │   │   │   ├── hparams
    │   │   │   │   │   └── train_fr.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   └── train.py
    │   │   │   └── transformer
    │   │   │       ├── common_voice_prepare.py -> ../../common_voice_prepare.py
    │   │   │       ├── hparams
    │   │   │       │   └── train_fr.yaml
    │   │   │       ├── README.md
    │   │   │       └── train.py
    │   │   └── common_voice_prepare.py
    │   ├── DNS
    │   │   ├── dns_prepare.py
    │   │   └── enhance
    │   │       └── spectral_map
    │   │           ├── dns_prepare.py -> ../../dns_prepare.py
    │   │           ├── extra_requirements.txt
    │   │           ├── hparams
    │   │           │   ├── params_CNNTransformer.yaml
    │   │           │   └── params_CNN.yaml
    │   │           ├── README.md
    │   │           └── train.py
    │   ├── ERPCore
    │   │   └── P3_decoding
    │   │       ├── download_required_data.py
    │   │       ├── extra_requirements.txt
    │   │       ├── prepare.py
    │   │       ├── README.md
    │   │       ├── train.py
    │   │       └── train.yaml
    │   ├── Fisher-Callhome-Spanish
    │   │   ├── extra_requirements.txt
    │   │   ├── fisher_callhome_prepare.py
    │   │   ├── README.md
    │   │   ├── ST
    │   │   │   └── transformer
    │   │   │       ├── hparams
    │   │   │       │   ├── conformer.yaml
    │   │   │       │   └── transformer.yaml
    │   │   │       └── train.py
    │   │   └── Tokenizer
    │   │       ├── fisher_callhome_prepare.py -> ../fisher_callhome_prepare.py
    │   │       ├── hparams
    │   │       │   └── train_bpe_1k.yaml
    │   │       └── train.py
    │   ├── fluent-speech-commands
    │   │   ├── direct
    │   │   │   ├── hparams
    │   │   │   │   └── train.yaml
    │   │   │   ├── prepare.py -> ../prepare.py
    │   │   │   └── train.py
    │   │   ├── extra_requirements.txt
    │   │   ├── prepare.py
    │   │   ├── README.md
    │   │   └── Tokenizer
    │   │       ├── hparams
    │   │       │   └── tokenizer_bpe51.yaml
    │   │       ├── prepare.py -> ../prepare.py
    │   │       └── train.py
    │   ├── Google-speech-commands
    │   │   ├── hparams
    │   │   │   └── xvect.yaml
    │   │   ├── prepare_GSC.py
    │   │   ├── README.md
    │   │   └── train.py
    │   ├── IEMOCAP
    │   │   ├── emotion_recognition
    │   │   │   ├── extra_dependencies.txt
    │   │   │   ├── hparams
    │   │   │   │   ├── train_with_wav2vec2.yaml
    │   │   │   │   └── train.yaml
    │   │   │   ├── iemocap_prepare.py
    │   │   │   ├── train.py
    │   │   │   └── train_with_wav2vec2.py
    │   │   └── README.md
    │   ├── LibriMix
    │   │   ├── extra-dependencies.txt
    │   │   ├── meta
    │   │   │   └── preprocess_dynamic_mixing.py
    │   │   ├── prepare_data.py
    │   │   └── separation
    │   │       ├── dynamic_mixing.py
    │   │       ├── hparams
    │   │       │   ├── sepformer-libri2mix.yaml
    │   │       │   └── sepformer-libri3mix.yaml
    │   │       ├── README.md
    │   │       └── train.py
    │   ├── LibriParty
    │   │   ├── generate_dataset
    │   │   │   ├── create_custom_dataset.py
    │   │   │   ├── dataset.yaml
    │   │   │   ├── download_required_data.py
    │   │   │   ├── get_dataset_from_metadata.py
    │   │   │   ├── local
    │   │   │   │   ├── create_mixtures_from_metadata.py
    │   │   │   │   ├── create_mixtures_metadata.py
    │   │   │   │   ├── __init__.py
    │   │   │   │   └── resample_folder.py
    │   │   │   └── README.md
    │   │   └── VAD
    │   │       ├── commonlanguage_prepare.py
    │   │       ├── data_augment.py
    │   │       ├── extra-dependencies.txt
    │   │       ├── hparams
    │   │       │   └── train.yaml
    │   │       ├── libriparty_prepare.py
    │   │       ├── musan_prepare.py
    │   │       ├── README.md
    │   │       └── train.py
    │   ├── LibriSpeech
    │   │   ├── ASR
    │   │   │   ├── ctc
    │   │   │   │   ├── hparams
    │   │   │   │   │   └── train_with_wav2vec.yaml
    │   │   │   │   ├── librispeech_prepare.py -> ../../librispeech_prepare.py
    │   │   │   │   ├── README.md
    │   │   │   │   └── train_with_wav2vec.py
    │   │   │   ├── seq2seq
    │   │   │   │   ├── hparams
    │   │   │   │   │   ├── train_BPE_1000.yaml
    │   │   │   │   │   └── train_BPE_5000.yaml
    │   │   │   │   ├── librispeech_prepare.py -> ../../librispeech_prepare.py
    │   │   │   │   ├── README.md
    │   │   │   │   └── train.py
    │   │   │   ├── transducer
    │   │   │   │   ├── hparams
    │   │   │   │   │   └── train.yaml
    │   │   │   │   ├── librispeech_prepare.py -> ../../librispeech_prepare.py
    │   │   │   │   ├── README.md
    │   │   │   │   └── train.py
    │   │   │   └── transformer
    │   │   │       ├── hparams
    │   │   │       │   ├── conformer_small.yaml
    │   │   │       │   └── transformer.yaml
    │   │   │       ├── librispeech_prepare.py -> ../../librispeech_prepare.py
    │   │   │       ├── README.md
    │   │   │       └── train.py
    │   │   ├── G2P
    │   │   │   ├── hparams
    │   │   │   │   └── train.yaml
    │   │   │   ├── librispeech_prepare.py -> ../librispeech_prepare.py
    │   │   │   ├── README.md
    │   │   │   └── train.py
    │   │   ├── librispeech_prepare.py
    │   │   ├── LM
    │   │   │   ├── dataset.py
    │   │   │   ├── extra_requirements.txt
    │   │   │   ├── hparams
    │   │   │   │   ├── RNNLM.yaml
    │   │   │   │   └── transformer.yaml
    │   │   │   ├── librispeech_prepare.py -> ../librispeech_prepare.py
    │   │   │   ├── README.md
    │   │   │   └── train.py
    │   │   ├── README.md
    │   │   └── Tokenizer
    │   │       ├── hparams
    │   │       │   ├── 1K_unigram_subword_bpe.yaml
    │   │       │   └── 5K_unigram_subword_bpe.yaml
    │   │       ├── librispeech_prepare.py -> ../librispeech_prepare.py
    │   │       ├── README.md
    │   │       └── train.py
    │   ├── REAL-M
    │   │   └── sisnr-estimation
    │   │       ├── hparams
    │   │       │   └── pool_sisnrestimator.yaml
    │   │       ├── README.md
    │   │       └── train.py
    │   ├── SLURP
    │   │   ├── direct
    │   │   │   ├── extra_dependencies.txt
    │   │   │   ├── hparams
    │   │   │   │   └── train.yaml
    │   │   │   ├── prepare.py -> ../prepare.py
    │   │   │   └── train.py
    │   │   ├── NLU
    │   │   │   ├── hparams
    │   │   │   │   └── train.yaml
    │   │   │   ├── prepare.py -> ../prepare.py
    │   │   │   └── train.py
    │   │   ├── prepare.py
    │   │   ├── README.md
    │   │   └── Tokenizer
    │   │       ├── hparams
    │   │       │   └── tokenizer_bpe58.yaml
    │   │       ├── prepare.py -> ../prepare.py
    │   │       └── train.py
    │   ├── timers-and-such
    │   │   ├── decoupled
    │   │   │   ├── hparams
    │   │   │   │   ├── train_LS_LM.yaml
    │   │   │   │   └── train_TAS_LM.yaml
    │   │   │   ├── prepare.py -> ../prepare.py
    │   │   │   ├── run_LS_LM.sh
    │   │   │   ├── run_TAS_LM.sh
    │   │   │   └── train.py
    │   │   ├── direct
    │   │   │   ├── hparams
    │   │   │   │   ├── train_with_wav2vec2.yaml
    │   │   │   │   └── train.yaml
    │   │   │   ├── prepare.py -> ../prepare.py
    │   │   │   ├── run.sh
    │   │   │   ├── train.py
    │   │   │   └── train_with_wav2vec2.py
    │   │   ├── extra_requirements.txt
    │   │   ├── LM
    │   │   │   ├── hparams
    │   │   │   │   └── train.yaml
    │   │   │   ├── prepare.py -> ../prepare.py
    │   │   │   └── train.py
    │   │   ├── multistage
    │   │   │   ├── hparams
    │   │   │   │   ├── train_LS_LM.yaml
    │   │   │   │   └── train_TAS_LM.yaml
    │   │   │   ├── prepare.py -> ../prepare.py
    │   │   │   ├── run_LS_LM.sh
    │   │   │   ├── run_TAS_LM.sh
    │   │   │   └── train.py
    │   │   ├── prepare.py
    │   │   ├── README.md
    │   │   └── Tokenizer
    │   │       ├── hparams
    │   │       │   └── tokenizer_bpe51.yaml
    │   │       ├── prepare.py -> ../prepare.py
    │   │       └── train.py
    │   ├── TIMIT
    │   │   ├── Alignment
    │   │   │   ├── hparams
    │   │   │   │   └── train.yaml
    │   │   │   ├── README.md
    │   │   │   ├── timit_prepare.py -> ../timit_prepare.py
    │   │   │   └── train.py
    │   │   ├── ASR
    │   │   │   ├── CTC
    │   │   │   │   ├── hparams
    │   │   │   │   │   └── train.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   ├── timit_prepare.py -> ../../timit_prepare.py
    │   │   │   │   └── train.py
    │   │   │   ├── seq2seq
    │   │   │   │   ├── extra_dependencies.txt
    │   │   │   │   ├── hparams
    │   │   │   │   │   ├── train_with_wav2vec2.yaml
    │   │   │   │   │   └── train.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   ├── timit_prepare.py -> ../../timit_prepare.py
    │   │   │   │   ├── train.py
    │   │   │   │   └── train_with_wav2vec2.py
    │   │   │   ├── seq2seq_knowledge_distillation
    │   │   │   │   ├── hparams
    │   │   │   │   │   ├── save_teachers.yaml
    │   │   │   │   │   ├── teachers
    │   │   │   │   │   │   ├── tea0.yaml
    │   │   │   │   │   │   ├── tea1.yaml
    │   │   │   │   │   │   ├── tea2.yaml
    │   │   │   │   │   │   ├── tea3.yaml
    │   │   │   │   │   │   ├── tea4.yaml
    │   │   │   │   │   │   ├── tea5.yaml
    │   │   │   │   │   │   ├── tea6.yaml
    │   │   │   │   │   │   ├── tea7.yaml
    │   │   │   │   │   │   ├── tea8.yaml
    │   │   │   │   │   │   └── tea9.yaml
    │   │   │   │   │   └── train_kd.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   ├── save_teachers.py
    │   │   │   │   ├── timit_prepare.py -> ../../timit_prepare.py
    │   │   │   │   ├── train_kd.py
    │   │   │   │   └── train_teacher.py
    │   │   │   └── transducer
    │   │   │       ├── extra_requirements.txt
    │   │   │       ├── hparams
    │   │   │       │   ├── train_wav2vec.yaml
    │   │   │       │   └── train.yaml
    │   │   │       ├── README.md
    │   │   │       ├── timit_prepare.py -> ../../timit_prepare.py
    │   │   │       ├── train.py
    │   │   │       └── train_wav2vec.py
    │   │   └── timit_prepare.py
    │   ├── UrbanSound8k
    │   │   ├── README.md
    │   │   ├── SoundClassification
    │   │   │   ├── confusion_matrix_fig.py
    │   │   │   ├── custom_model.py
    │   │   │   ├── extra_dependencies.txt
    │   │   │   ├── hparams
    │   │   │   │   └── train_ecapa_tdnn.yaml
    │   │   │   ├── train.py
    │   │   │   ├── UrbanSound8k
    │   │   │   │   ├── FREESOUNDCREDITS.txt
    │   │   │   │   ├── metadata
    │   │   │   │   │   ├── UrbanSound8K.csv
    │   │   │   │   │   └── UrbanSound8k_speechbrain.csv
    │   │   │   │   └── UrbanSound8K_README.txt
    │   │   │   └── urbansound8k_prepare.py -> ../urbansound8k_prepare.py
    │   │   └── urbansound8k_prepare.py
    │   ├── Voicebank
    │   │   ├── ASR
    │   │   │   └── CTC
    │   │   │       ├── hparams
    │   │   │       │   └── train.yaml
    │   │   │       ├── README.md
    │   │   │       ├── train.py
    │   │   │       └── voicebank_prepare.py -> ../../voicebank_prepare.py
    │   │   ├── enhance
    │   │   │   ├── MetricGAN
    │   │   │   │   ├── hparams
    │   │   │   │   │   └── train.yaml
    │   │   │   │   ├── models
    │   │   │   │   │   └── MetricGAN.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   ├── train.py
    │   │   │   │   └── voicebank_prepare.py -> ../../voicebank_prepare.py
    │   │   │   ├── SEGAN
    │   │   │   │   ├── hparams
    │   │   │   │   │   └── train.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   ├── train.py
    │   │   │   │   └── voicebank_prepare.py -> ../../voicebank_prepare.py
    │   │   │   ├── spectral_mask
    │   │   │   │   ├── hparams
    │   │   │   │   │   ├── models
    │   │   │   │   │   │   ├── 2DFCN+BLSTM.yaml
    │   │   │   │   │   │   ├── 2DFCN.yaml
    │   │   │   │   │   │   ├── BLSTM.yaml
    │   │   │   │   │   │   └── CNNTransformer.yaml
    │   │   │   │   │   └── train.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   ├── train.py
    │   │   │   │   └── voicebank_prepare.py -> ../../voicebank_prepare.py
    │   │   │   └── waveform_map
    │   │   │       ├── hparams
    │   │   │       │   ├── models
    │   │   │       │   │   └── FCN.yaml
    │   │   │       │   └── train.yaml
    │   │   │       ├── README.md
    │   │   │       ├── train.py
    │   │   │       └── voicebank_prepare.py -> ../../voicebank_prepare.py
    │   │   ├── MTL
    │   │   │   ├── ASR_enhance
    │   │   │   │   ├── extra_requirements.txt
    │   │   │   │   ├── hparams
    │   │   │   │   │   ├── enhance_mimic.yaml
    │   │   │   │   │   ├── models
    │   │   │   │   │   │   ├── asr_model.yaml
    │   │   │   │   │   │   ├── crdnn_enhance.yaml
    │   │   │   │   │   │   ├── enhance_model.yaml
    │   │   │   │   │   │   └── perceptual_model.yaml
    │   │   │   │   │   ├── pretrain_perceptual.yaml
    │   │   │   │   │   └── robust_asr.yaml
    │   │   │   │   ├── README.md
    │   │   │   │   ├── train.py
    │   │   │   │   └── voicebank_prepare.py -> ../../voicebank_prepare.py
    │   │   │   └── CoopNet
    │   │   │       ├── CoopNet.py
    │   │   │       ├── extra-dependencies.txt
    │   │   │       ├── hparams
    │   │   │       │   ├── logger.yaml
    │   │   │       │   ├── models
    │   │   │       │   │   ├── asr_model.yaml
    │   │   │       │   │   ├── attention_model.yaml
    │   │   │       │   │   ├── enhance_model.yaml
    │   │   │       │   │   └── skip_connections.yaml
    │   │   │       │   ├── pretrain_1layer.yaml
    │   │   │       │   ├── pretrain_asr_and_se.yaml
    │   │   │       │   └── train_3layer.yaml
    │   │   │       ├── README.md
    │   │   │       ├── train.py
    │   │   │       └── voicebank_prepare.py -> ../../voicebank_prepare.py
    │   │   └── voicebank_prepare.py
    │   ├── VoxCeleb
    │   │   ├── SpeakerRec
    │   │   │   ├── hparams
    │   │   │   │   ├── train_ecapa_tdnn.yaml
    │   │   │   │   ├── train_x_vectors.yaml
    │   │   │   │   ├── verification_ecapa.yaml
    │   │   │   │   └── verification_plda_xvector.yaml
    │   │   │   ├── README.md
    │   │   │   ├── speaker_verification_cosine.py
    │   │   │   ├── speaker_verification_plda.py
    │   │   │   ├── train_speaker_embeddings.py
    │   │   │   └── voxceleb_prepare.py -> ../voxceleb_prepare.py
    │   │   └── voxceleb_prepare.py
    │   ├── VoxLingua107
    │   │   ├── lang_id
    │   │   │   ├── create_wds_shards.py
    │   │   │   ├── extra-dependencies.txt
    │   │   │   ├── hparams
    │   │   │   │   └── train_ecapa.yaml
    │   │   │   ├── README.md
    │   │   │   └── train.py
    │   │   └── README.md
    │   ├── WHAMandWHAMR
    │   │   ├── extra-dependencies.txt
    │   │   ├── meta
    │   │   │   ├── activlev.m
    │   │   │   ├── create_whamr_rirs.py
    │   │   │   ├── maxfilt.m
    │   │   │   ├── preprocess_dynamic_mixing.py
    │   │   │   ├── README.md
    │   │   │   ├── rir_constants.py
    │   │   │   └── wham_room.py
    │   │   ├── prepare_data.py
    │   │   └── separation
    │   │       ├── dynamic_mixing.py
    │   │       ├── hparams
    │   │       │   ├── sepformer-whamr.yaml
    │   │       │   └── sepformer-wham.yaml
    │   │       ├── README.md
    │   │       └── train.py
    │   └── WSJ0Mix
    │       ├── extra-dependencies.txt
    │       ├── meta
    │       │   └── preprocess_dynamic_mixing.py
    │       ├── prepare_data.py
    │       └── separation
    │           ├── dynamic_mixing.py
    │           ├── hparams
    │           │   ├── convtasnet.yaml
    │           │   ├── dprnn.yaml
    │           │   ├── sepformer-customdataset.yaml
    │           │   └── sepformer.yaml
    │           ├── README.md
    │           └── train.py
    ├── requirements.txt
    ├── samples
    │   ├── audio_samples
    │   │   ├── csv_example2.csv
    │   │   ├── csv_example3.csv
    │   │   ├── csv_example.csv
    │   │   ├── csv_example_multichannel.csv
    │   │   ├── example1.wav
    │   │   ├── example2.flac
    │   │   ├── example3.sph
    │   │   ├── example4.raw
    │   │   ├── example5.wav
    │   │   ├── example6.wav
    │   │   ├── example_fr.wav
    │   │   ├── example_multichannel.wav
    │   │   ├── example_noisy.wav
    │   │   ├── multi_mic
    │   │   │   ├── noise_0.70225_-0.70225_0.11704.flac
    │   │   │   ├── noise_diffuse.flac
    │   │   │   ├── speech_-0.82918_0.55279_-0.082918.flac
    │   │   │   └── speech_-0.98894_0_0.14834.flac
    │   │   ├── nn_training_samples
    │   │   │   ├── debug.csv
    │   │   │   ├── dev.csv
    │   │   │   ├── dev.json
    │   │   │   ├── spk1_snt1.pkl
    │   │   │   ├── spk1_snt1.wav
    │   │   │   ├── spk1_snt2.pkl
    │   │   │   ├── spk1_snt2.wav
    │   │   │   ├── spk1_snt3.pkl
    │   │   │   ├── spk1_snt3.wav
    │   │   │   ├── spk1_snt4.pkl
    │   │   │   ├── spk1_snt4.wav
    │   │   │   ├── spk1_snt5.pkl
    │   │   │   ├── spk1_snt5.wav
    │   │   │   ├── spk1_snt6.pkl
    │   │   │   ├── spk1_snt6.wav
    │   │   │   ├── spk2_snt1.pkl
    │   │   │   ├── spk2_snt1.wav
    │   │   │   ├── spk2_snt2.pkl
    │   │   │   ├── spk2_snt2.wav
    │   │   │   ├── spk2_snt3.pkl
    │   │   │   ├── spk2_snt3.wav
    │   │   │   ├── spk2_snt4.pkl
    │   │   │   ├── spk2_snt4.wav
    │   │   │   ├── spk2_snt5.pkl
    │   │   │   ├── spk2_snt5.wav
    │   │   │   ├── spk2_snt6.pkl
    │   │   │   ├── spk2_snt6.wav
    │   │   │   ├── test.csv
    │   │   │   ├── train.csv
    │   │   │   └── train.json
    │   │   ├── sourcesep_samples
    │   │   │   ├── csv_example_sourcesep_mixture.csv
    │   │   │   ├── csv_example_sourcesep_source1.csv
    │   │   │   ├── csv_example_sourcesep_source2.csv
    │   │   │   ├── minimal_example_convtasnet_cv.csv
    │   │   │   ├── minimal_example_convtasnet_tr.csv
    │   │   │   ├── minimal_example_convtasnet_tt.csv
    │   │   │   ├── mixture_0.wav
    │   │   │   ├── mixture_1.wav
    │   │   │   ├── mixture_2.wav
    │   │   │   ├── mixture_3.wav
    │   │   │   ├── source1_0.wav
    │   │   │   ├── source1_1.wav
    │   │   │   ├── source1_2.wav
    │   │   │   ├── source1_3.wav
    │   │   │   ├── source2_0.wav
    │   │   │   ├── source2_1.wav
    │   │   │   ├── source2_2.wav
    │   │   │   └── source2_3.wav
    │   │   ├── test_csv_merge.csv
    │   │   ├── test_mixture.wav
    │   │   └── vad
    │   │       ├── train.json
    │   │       ├── train.wav
    │   │       ├── valid.json
    │   │       └── valid.wav
    │   ├── label_samples
    │   │   ├── hyp.csv
    │   │   └── ref.csv
    │   ├── noise_samples
    │   │   ├── noise1.wav
    │   │   ├── noise2.wav
    │   │   ├── noise3.wav
    │   │   ├── noise4.wav
    │   │   ├── noise5.wav
    │   │   ├── noise.csv
    │   │   ├── noise_multichannel.csv
    │   │   ├── noise_multichannel.wav
    │   │   └── noise_rel.csv
    │   ├── plda_xvect_samples
    │   │   ├── enrol_stat_xvect.pkl
    │   │   ├── expected_plda_scores.pkl
    │   │   ├── test_stat_xvect.pkl
    │   │   └── train_stat_xvect.pkl
    │   ├── rir_samples
    │   │   ├── rir1.wav
    │   │   ├── rir2.wav
    │   │   ├── rir3.wav
    │   │   ├── rir4.wav
    │   │   ├── rir_multichannel.csv
    │   │   ├── rir_multichannel.wav
    │   │   ├── rirs.csv
    │   │   └── rirs_rel.csv
    │   ├── rttm_samples
    │   │   ├── ReadMe.md
    │   │   ├── ref_rttm
    │   │   │   └── ES2014c.rttm
    │   │   └── sys_rttm
    │   │       └── ES2014c.rttm
    │   ├── text_samples
    │   │   ├── hdf5_example.h5
    │   │   ├── label_dict.pkl
    │   │   └── readme.txt
    │   └── voxceleb_samples
    │       ├── meta
    │       │   └── iden_split.txt
    │       ├── readme.txt
    │       └── wav
    │           ├── dev.csv
    │           ├── id10001
    │           │   └── 1zcIwhmdeo4
    │           │       ├── 00001.wav
    │           │       ├── 00002.wav
    │           │       └── 00003.wav
    │           ├── id10002
    │           │   └── xTV-jFAUKcw
    │           │       ├── 00001.wav
    │           │       ├── 00002.wav
    │           │       └── 00003.wav
    │           └── train.csv
    ├── setup.py
    ├── speechbrain
    │   ├── alignment
    │   │   ├── aligner.py
    │   │   ├── ctc_segmentation.py
    │   │   └── __init__.py
    │   ├── core.py
    │   ├── dataio
    │   │   ├── batch.py
    │   │   ├── dataio.py
    │   │   ├── dataloader.py
    │   │   ├── dataset.py
    │   │   ├── encoder.py
    │   │   ├── __init__.py
    │   │   ├── iterators.py
    │   │   ├── legacy.py
    │   │   ├── preprocess.py
    │   │   ├── sampler.py
    │   │   └── wer.py
    │   ├── decoders
    │   │   ├── ctc.py
    │   │   ├── __init__.py
    │   │   ├── seq2seq.py
    │   │   └── transducer.py
    │   ├── __init__.py
    │   ├── lm
    │   │   ├── arpa.py
    │   │   ├── counting.py
    │   │   ├── __init__.py
    │   │   └── ngram.py
    │   ├── lobes
    │   │   ├── augment.py
    │   │   ├── beamform_multimic.py
    │   │   ├── features.py
    │   │   ├── __init__.py
    │   │   └── models
    │   │       ├── ContextNet.py
    │   │       ├── convolution.py
    │   │       ├── conv_tasnet.py
    │   │       ├── CRDNN.py
    │   │       ├── dual_path.py
    │   │       ├── ECAPA_TDNN.py
    │   │       ├── ESPnetVGG.py
    │   │       ├── fairseq_wav2vec.py
    │   │       ├── huggingface_wav2vec.py
    │   │       ├── __init__.py
    │   │       ├── MetricGAN.py
    │   │       ├── RNNLM.py
    │   │       ├── segan_model.py
    │   │       ├── transformer
    │   │       │   ├── Conformer.py
    │   │       │   ├── __init__.py
    │   │       │   ├── TransformerASR.py
    │   │       │   ├── TransformerLM.py
    │   │       │   ├── Transformer.py
    │   │       │   ├── TransformerSE.py
    │   │       │   └── TransformerST.py
    │   │       ├── VanillaNN.py
    │   │       └── Xvector.py
    │   ├── log-config.yaml
    │   ├── nnet
    │   │   ├── activations.py
    │   │   ├── attention.py
    │   │   ├── CNN.py
    │   │   ├── complex_networks
    │   │   │   ├── c_CNN.py
    │   │   │   ├── c_linear.py
    │   │   │   ├── c_normalization.py
    │   │   │   ├── c_ops.py
    │   │   │   ├── c_RNN.py
    │   │   │   └── __init__.py
    │   │   ├── containers.py
    │   │   ├── dropout.py
    │   │   ├── embedding.py
    │   │   ├── __init__.py
    │   │   ├── linear.py
    │   │   ├── loss
    │   │   │   ├── guidedattn_loss.py
    │   │   │   ├── __init__.py
    │   │   │   ├── stoi_loss.py
    │   │   │   └── transducer_loss.py
    │   │   ├── losses.py
    │   │   ├── normalization.py
    │   │   ├── pooling.py
    │   │   ├── quaternion_networks
    │   │   │   ├── __init__.py
    │   │   │   ├── q_CNN.py
    │   │   │   ├── q_linear.py
    │   │   │   ├── q_normalization.py
    │   │   │   ├── q_ops.py
    │   │   │   └── q_RNN.py
    │   │   ├── RNN.py
    │   │   ├── schedulers.py
    │   │   └── transducer
    │   │       ├── __init__.py
    │   │       └── transducer_joint.py
    │   ├── pretrained
    │   │   ├── fetching.py
    │   │   ├── __init__.py
    │   │   └── interfaces.py
    │   ├── processing
    │   │   ├── decomposition.py
    │   │   ├── diarization.py
    │   │   ├── features.py
    │   │   ├── __init__.py
    │   │   ├── multi_mic.py
    │   │   ├── NMF.py
    │   │   ├── PLDA_LDA.py
    │   │   ├── signal_processing.py
    │   │   └── speech_augmentation.py
    │   ├── tokenizers
    │   │   ├── __init__.py
    │   │   └── SentencePiece.py
    │   ├── utils
    │   │   ├── Accuracy.py
    │   │   ├── bleu.py
    │   │   ├── callchains.py
    │   │   ├── checkpoints.py
    │   │   ├── data_pipeline.py
    │   │   ├── data_utils.py
    │   │   ├── depgraph.py
    │   │   ├── DER.py
    │   │   ├── distributed.py
    │   │   ├── edit_distance.py
    │   │   ├── epoch_loop.py
    │   │   ├── __init__.py
    │   │   ├── logger.py
    │   │   ├── metric_stats.py
    │   │   ├── parameter_transfer.py
    │   │   ├── superpowers.py
    │   │   ├── torch_audio_backend.py
    │   │   └── train_logger.py
    │   └── version.txt
    ├── templates
    │   ├── enhancement
    │   │   ├── custom_model.py
    │   │   ├── mini_librispeech_prepare.py
    │   │   ├── README.md
    │   │   ├── train.py
    │   │   └── train.yaml
    │   ├── README.md
    │   ├── speaker_id
    │   │   ├── custom_model.py
    │   │   ├── mini_librispeech_prepare.py
    │   │   ├── README.md
    │   │   ├── train.py
    │   │   └── train.yaml
    │   └── speech_recognition
    │       ├── ASR
    │       │   ├── mini_librispeech_prepare.py -> ../mini_librispeech_prepare.py
    │       │   ├── README.md
    │       │   ├── train.py
    │       │   └── train.yaml
    │       ├── LM
    │       │   ├── custom_model.py
    │       │   ├── data
    │       │   │   ├── test.txt
    │       │   │   ├── train.txt
    │       │   │   └── valid.txt
    │       │   ├── extra_requirements.txt
    │       │   ├── README.md
    │       │   ├── RNNLM.yaml
    │       │   └── train.py
    │       ├── mini_librispeech_prepare.py
    │       ├── README.md
    │       └── Tokenizer
    │           ├── mini_librispeech_prepare.py -> ../mini_librispeech_prepare.py
    │           ├── README.md
    │           ├── tokenizer.yaml
    │           └── train.py
    ├── tests
    │   ├── integration
    │   │   ├── neural_networks
    │   │   │   ├── ASR_alignment_forward
    │   │   │   │   ├── example_asr_alignment_forward_experiment.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── ASR_alignment_viterbi
    │   │   │   │   ├── example_asr_alignment_viterbi_experiment.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── ASR_CTC
    │   │   │   │   ├── example_asr_ctc_experiment_complex_net.py
    │   │   │   │   ├── example_asr_ctc_experiment.py
    │   │   │   │   ├── example_asr_ctc_experiment_quaternion_net.py
    │   │   │   │   ├── hyperparams_complex_net.yaml
    │   │   │   │   ├── hyperparams_quaternion_net.yaml
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── ASR_DNN_HMM
    │   │   │   │   ├── example_asr_dnn_hmm_experiment.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── ASR_seq2seq
    │   │   │   │   ├── example_asr_seq2seq_experiment.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── ASR_Transducer
    │   │   │   │   ├── example_asr_transducer_experiment.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── autoencoder
    │   │   │   │   ├── example_auto_experiment.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── enhance_GAN
    │   │   │   │   ├── example_enhance_gan_experiment.py
    │   │   │   │   ├── hyperparams.yaml
    │   │   │   │   └── models.yaml
    │   │   │   ├── G2P
    │   │   │   │   ├── example_g2p.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── LM_RNN
    │   │   │   │   ├── example_lm_rnn_experiment.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── separation
    │   │   │   │   ├── example_conv_tasnet.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   ├── speaker_id
    │   │   │   │   ├── example_xvector_experiment.py
    │   │   │   │   └── hyperparams.yaml
    │   │   │   └── VAD
    │   │   │       ├── example_vad.py
    │   │   │       └── hyperparams.yaml
    │   │   └── signal_processing
    │   │       ├── example_add_babble.py
    │   │       ├── example_add_noise.py
    │   │       ├── example_add_reverb.py
    │   │       ├── example_do_clip.py
    │   │       ├── example_drop_chunk.py
    │   │       ├── example_drop_freq.py
    │   │       ├── example_speed_perturb.py
    │   │       ├── expected
    │   │       │   ├── add_babble
    │   │       │   │   └── save
    │   │       │   │       └── example1.flac
    │   │       │   ├── add_noise
    │   │       │   │   └── save
    │   │       │   │       └── example1.flac
    │   │       │   ├── add_reverb
    │   │       │   │   └── save
    │   │       │   │       └── example1.flac
    │   │       │   ├── do_clip
    │   │       │   │   └── save
    │   │       │   │       └── example1.flac
    │   │       │   ├── drop_chunk
    │   │       │   │   └── save
    │   │       │   │       └── example1.flac
    │   │       │   ├── drop_freq
    │   │       │   │   └── save
    │   │       │   │       └── example1.flac
    │   │       │   └── speed_perturb
    │   │       │       └── save
    │   │       │           └── example1.flac
    │   │       ├── hyperparams.yaml
    │   │       ├── nmf_sourcesep
    │   │       │   ├── example_experiment.py
    │   │       │   └── hyperparams.yaml
    │   │       └── PLDA_xvector
    │   │           └── example_plda_experiment.py
    │   └── unittests
    │       ├── test_activations.py
    │       ├── test_arpa.py
    │       ├── test_attention.py
    │       ├── test_augment.py
    │       ├── test_batching.py
    │       ├── test_callchains.py
    │       ├── test_categorical_encoder.py
    │       ├── test_checkpoints.py
    │       ├── test_CNN.py
    │       ├── test_core.py
    │       ├── test_counting.py
    │       ├── test_ctc_segmentation.py
    │       ├── test_data_io.py
    │       ├── test_dataloader.py
    │       ├── test_data_pipeline.py
    │       ├── test_dataset.py
    │       ├── test_dependency_graph.py
    │       ├── test_dropout.py
    │       ├── test_edit_distance.py
    │       ├── test_embedding.py
    │       ├── test_epoch_loop.py
    │       ├── test_features.py
    │       ├── test_linear.py
    │       ├── test_losses.py
    │       ├── test_metrics.py
    │       ├── test_multi_mic.py
    │       ├── test_ngram_lm.py
    │       ├── test_normalization.py
    │       ├── test_pooling.py
    │       ├── test_pretrainer.py
    │       ├── test_RNN.py
    │       ├── test_samplers.py
    │       ├── test_schedulers.py
    │       ├── test_signal_processing.py
    │       ├── test_superpowers.py
    │       ├── test_tokenizer.py
    │       └── tokenizer_data
    │           └── dev-clean.csv
    └── tools
        ├── compute_wer.py
        └── der_eval
            └── md-eval.pl
